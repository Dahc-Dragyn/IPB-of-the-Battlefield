{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib  # For model saving/loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictiveModel:\n",
    "    def __init__(self, model_path: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the PredictiveModel.\n",
    "\n",
    "        Args:\n",
    "            model_path (str, optional): Path to a pre-trained model. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.info(\"Initializing Predictive Model\")\n",
    "\n",
    "        # Initialize the model (Random Forest) with Pipeline and ColumnTransformer\n",
    "        self.model = Pipeline(steps=[\n",
    "            ('preprocessor', ColumnTransformer(transformers=[\n",
    "                ('num', Pipeline(steps=[\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing numerical values\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]), ['terrain_feature_1', 'terrain_feature_2', 'orbat_strength']),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), ['weather_condition', 'previous_op_outcome'])\n",
    "            ])),\n",
    "            ('classifier', RandomForestClassifier(random_state=42))\n",
    "        ])\n",
    "\n",
    "        # Load pre-trained model if model_path is provided\n",
    "        if model_path:\n",
    "            self.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, orbat_data: list, terrain_features: list, previous_ops: list) -> None:\n",
    "        \"\"\"\n",
    "        Trains the predictive model using historical data.\n",
    "\n",
    "        Args:\n",
    "            orbat_data (list): Data on enemy order of battle.\n",
    "            terrain_features (list): Extracted terrain features from TerrainAnalysisModel.\n",
    "            previous_ops (list): Data from previous operations.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Training Predictive Model\")\n",
    "\n",
    "        try:\n",
    "            # 1. Data Preprocessing\n",
    "            X, y = self.preprocess_data(orbat_data, terrain_features, previous_ops)\n",
    "\n",
    "            # 2. Cross-validation\n",
    "            self.logger.info(\"Performing cross-validation\")\n",
    "            cv_scores = cross_val_score(self.model, X, y, cv=5, scoring='accuracy')\n",
    "            mean_accuracy = cv_scores.mean()\n",
    "            self.logger.info(\"Cross-Validation Accuracy Scores: %s\", cv_scores)\n",
    "            self.logger.info(\"Mean Cross-Validation Accuracy: %.4f\", mean_accuracy)\n",
    "\n",
    "            # 3. Fit the model on the entire dataset after cross-validation\n",
    "            self.model.fit(X, y)\n",
    "            self.logger.info(\"Model training completed\")\n",
    "\n",
    "            # 4. Feature Importances\n",
    "            self.log_feature_importances()\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error during training: %s\", e)\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, orbat_data: list, terrain_features: list, previous_ops: list) -> list:\n",
    "        \"\"\"\n",
    "        Predicts enemy courses of action (COAs).\n",
    "\n",
    "        Args:\n",
    "            orbat_data (list): Current enemy order of battle data.\n",
    "            terrain_features (list): Terrain features of the area of operations.\n",
    "            previous_ops (list): Data from previous operations.\n",
    "\n",
    "        Returns:\n",
    "            list: Predicted enemy COAs.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Predicting Enemy Courses of Action\")\n",
    "\n",
    "        try:\n",
    "            # 1. Data Preprocessing\n",
    "            X_new = self.preprocess_data(orbat_data, terrain_features, previous_ops, for_training=False)\n",
    "\n",
    "            # 2. Make Predictions\n",
    "            predicted_coas = self.model.predict(X_new)\n",
    "\n",
    "            # 3. Convert Indices to COA Labels (if necessary)\n",
    "            # Example: Assuming COA labels are already meaningful\n",
    "            return predicted_coas.tolist()\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error during prediction: %s\", e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(self, orbat_data: list, terrain_features: list, previous_ops: list, for_training: bool = True):\n",
    "        \"\"\"\n",
    "        Preprocesses the data for training and prediction.\n",
    "\n",
    "        Args:\n",
    "            orbat_data (list): Enemy order of battle data.\n",
    "            terrain_features (list): Extracted terrain features.\n",
    "            previous_ops (list): Data from previous operations.\n",
    "            for_training (bool, optional): Whether the preprocessing is for training or prediction. \n",
    "                                            Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            tuple or pd.DataFrame: Feature matrix (X) and target variable (y) for training,\n",
    "                                   or feature matrix (X) for prediction.\n",
    "        \"\"\"\n",
    "        # Convert input lists to DataFrames\n",
    "        orbat_df = pd.DataFrame(orbat_data, columns=['unit_type', 'orbat_strength'])\n",
    "        terrain_df = pd.DataFrame(terrain_features, columns=['terrain_feature_1', 'terrain_feature_2'])  # Example features\n",
    "        previous_ops_df = pd.DataFrame(previous_ops, columns=['weather_condition', 'previous_op_outcome', 'coa_taken'])\n",
    "\n",
    "        # Combine data sources\n",
    "        if for_training:\n",
    "            df = pd.concat([orbat_df, terrain_df, previous_ops_df], axis=1)\n",
    "        else:\n",
    "            # For prediction, exclude 'coa_taken'\n",
    "            previous_ops_df = previous_ops_df.drop(columns=['coa_taken'], errors='ignore')\n",
    "            df = pd.concat([orbat_df, terrain_df, previous_ops_df], axis=1)\n",
    "\n",
    "        # Validate required columns\n",
    "        required_columns = ['terrain_feature_1', 'terrain_feature_2', 'orbat_strength', 'weather_condition', 'previous_op_outcome']\n",
    "        if for_training:\n",
    "            required_columns.append('coa_taken')\n",
    "\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            self.logger.error(\"Missing columns in input data: %s\", missing_columns)\n",
    "            raise ValueError(f\"Missing columns in input data: {missing_columns}\")\n",
    "\n",
    "        if for_training:\n",
    "            X = df[['terrain_feature_1', 'terrain_feature_2', 'orbat_strength', 'weather_condition', 'previous_op_outcome']]\n",
    "            y = df['coa_taken']  # Target variable\n",
    "            return X, y\n",
    "        else:\n",
    "            X = df[['terrain_feature_1', 'terrain_feature_2', 'orbat_strength', 'weather_condition', 'previous_op_outcome']]\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(self, model_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Saves the trained model to a file.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to save the model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            joblib.dump(self.model, model_path)\n",
    "            self.logger.info(\"Model saved to %s\", model_path)\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Failed to save model to %s: %s\", model_path, e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(self, model_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Loads a pre-trained model from a file.\n",
    "\n",
    "        Args:\n",
    "            model_path (str): Path to the saved model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model = joblib.load(model_path)\n",
    "            self.logger.info(\"Model loaded from %s\", model_path)\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(\"Model file not found at %s\", model_path)\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error loading model: %s\", e)\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_feature_importances(self) -> None:\n",
    "        \"\"\"\n",
    "        Logs the feature importances from the trained Random Forest model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            classifier = self.model.named_steps['classifier']\n",
    "            feature_names_num = self.model.named_steps['preprocessor'].transformers_[0][1].named_steps['scaler'].get_feature_names_out(['terrain_feature_1', 'terrain_feature_2', 'orbat_strength']).tolist()\n",
    "            feature_names_cat = self.model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(['weather_condition', 'previous_op_outcome']).tolist()\n",
    "            feature_names = feature_names_num + feature_names_cat\n",
    "\n",
    "            feature_importances = classifier.feature_importances_\n",
    "            feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "            # Sort features by importance\n",
    "            sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "            self.logger.info(\"Feature Importances:\")\n",
    "            for feature, importance in sorted_features:\n",
    "                self.logger.info(f\"{feature}: {importance:.4f}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error logging feature importances: %s\", e)\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
